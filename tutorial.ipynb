{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0a6c772",
   "metadata": {},
   "source": [
    "<pre>Created by David C. Heson for the University of Alabama at Birmingham Physics REU 2023.</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67124265",
   "metadata": {},
   "source": [
    "Website: https://cecas.clemson.edu/~ahoover/stare/\n",
    "Diagnosis: \n",
    "im0057\t10  7\t\tHypertensive Retinopathy??? OR Background Diabetic Retinopathy\n",
    "\n",
    "![Data Example](data_ex.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97577cf8",
   "metadata": {},
   "source": [
    "Problem Statement: Say there is an issue with your scanner, and when your data should look like the image above, it just ends up looking like this:\n",
    "![Distorted data :( ](distorted.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2750727",
   "metadata": {},
   "source": [
    "Alternative problem statement:\n",
    "![Distorted data 2 :( ](distorted_2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8407ab9b",
   "metadata": {},
   "source": [
    "[Original U-Net Paper](https://arxiv.org/pdf/1505.04597.pdf)\n",
    "![Original U-Net model as per the paper](og_unet_model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8453db95",
   "metadata": {},
   "source": [
    "A lot of Machine Learning (particularly in Python) is done by using pre-built models and simply adjusting them. Most tutorials that actually go through the layers are <i> very strongly </i> inspired by the tutorial on the official Keras website ([here](https://keras.io/examples/vision/oxford_pets_image_segmentation/)), which I will also be closely following regarding the construction of the model itself.\n",
    "\n",
    "U-Net Models were designed for <i> image segmentation </i>, which means they can identify the margins of different entities within an image. Take the below example of a cat and the mask created for a cat by a U-Net model.\n",
    "\n",
    "![Cat (credit to Keras tutorial)](cat.jpeg)\n",
    "![Cat + mask (credit to Keras tutorial)](cat_mask.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcca88c",
   "metadata": {},
   "source": [
    "95% of Machine Learning work, especially when it comes to image processing, is data preparation. We have to create data which contains relevant <i> information </i> for our task at hand, and also make it such that the model can parse through it efficiently and cleanly. We can also try to enhance our data set by extrapolating from existing data (within ethical and logical bounds).\n",
    "\n",
    "First of all, we need to parse through the data set. We know the two possible diagnoses on the image (code 7 and 10), and so we can select only images from the data set which have 7, 10, or both as possible diagnoses. \n",
    "\n",
    "The website provides a full list of diagnoses, which we can download as a .txt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f66861",
   "metadata": {},
   "outputs": [],
   "source": [
    "### import diagnoses codes as a .txt\n",
    "\n",
    "import requests\n",
    "\n",
    "def download_website(url, output_file):\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        with open(output_file, 'w') as file:\n",
    "            file.write(response.text)\n",
    "    else:\n",
    "        print(\"Failed to download website.\")\n",
    "\n",
    "url = 'https://cecas.clemson.edu/~ahoover/stare/diagnoses/all-mg-codes.txt'\n",
    "output_file = 'diagnoses.txt'\n",
    "\n",
    "download_website(url, output_file)\n",
    "\n",
    "with open('diagnoses.txt', 'r') as file:\n",
    "    contents = file.read()\n",
    "    print(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093ec447",
   "metadata": {},
   "outputs": [],
   "source": [
    "### parse through downloaded .txt to find the images that correspond to our diagnoses\n",
    "\n",
    "selected_images = []\n",
    "\n",
    "with open('diagnoses.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        image_info = line.split('\\t')\n",
    "        image_name = image_info[0]\n",
    "        integers = image_info[1].split()\n",
    "\n",
    "        if '10' in integers or '7' in integers:\n",
    "            selected_images.append(image_name + '.ppm')\n",
    "\n",
    "print(selected_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e9806b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### I will be a bit inneficient here. I will now just copy over these images to a new folder.\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def copy_files(file_list, source_folder, destination_folder):\n",
    "    for file_name in file_list:\n",
    "        source_path = os.path.join(source_folder, file_name)\n",
    "        destination_path = os.path.join(destination_folder, file_name)\n",
    "        \n",
    "        if os.path.exists(source_path):\n",
    "            shutil.copy(source_path, destination_path)\n",
    "        else:\n",
    "            print(f\"File '{file_name}' does not exist in the source folder.\")\n",
    "\n",
    "copy_files(selected_images, 'all-images', 'selected-images')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c861f138",
   "metadata": {},
   "source": [
    "The original U-Net Model does image segmentation, which means that it identifies regions of space which fit within specific shapes. However, with some altering of the layers the output can be designated as the image itself. \n",
    "\n",
    "[This](https://github.com/g2archie/UNet-MRI-Reconstruction) model does just so, created for MRI image reconstruction. We will simply use the model they created and adjust it to fit to our data.\n",
    "\n",
    "![Modified UNet](modified_unet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f848be7",
   "metadata": {},
   "source": [
    "Now, for the model...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229fc44b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b2027dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "### layers\n",
    "\n",
    "def _bernoulli(shape, mean):\n",
    "    return tf.nn.relu(tf.sign(mean - tf.random.uniform(shape, minval=0, maxval=1, dtype=tf.float32)))\n",
    "\n",
    "\n",
    "class DropBlock2D(tf.keras.layers.Layer):\n",
    "    def __init__(self, keep_prob, block_size, scale=True, **kwargs):\n",
    "        super(DropBlock2D, self).__init__(**kwargs)\n",
    "        self.keep_prob = float(keep_prob) if isinstance(keep_prob, int) else keep_prob\n",
    "        self.block_size = int(block_size)\n",
    "        self.scale = tf.constant(scale, dtype=tf.bool) if isinstance(scale, bool) else scale\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 4\n",
    "        _, self.h, self.w, self.channel = input_shape.as_list()\n",
    "        # pad the mask\n",
    "        p1 = (self.block_size - 1) // 2\n",
    "        p0 = (self.block_size - 1) - p1\n",
    "        self.padding = [[0, 0], [p0, p1], [p0, p1], [0, 0]]\n",
    "        self.set_keep_prob()\n",
    "        super(DropBlock2D, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs, training=None, **kwargs):\n",
    "        def drop():\n",
    "            mask = self._create_mask(tf.shape(inputs))\n",
    "            output = inputs * mask\n",
    "            output = tf.cond(self.scale,\n",
    "                             true_fn=lambda: output * tf.cast(tf.size(mask), tf.float32) / tf.reduce_sum(mask),\n",
    "                             false_fn=lambda: output)\n",
    "            return output\n",
    "\n",
    "        if training is None:\n",
    "            training = K.learning_phase()\n",
    "        output = tf.cond(tf.logical_or(tf.logical_not(training), tf.equal(self.keep_prob, 1.0)),\n",
    "                         true_fn=lambda: inputs,\n",
    "                         false_fn=drop)\n",
    "        return output\n",
    "\n",
    "    def set_keep_prob(self, keep_prob=None):\n",
    "        \"\"\"This method only supports Eager Execution\"\"\"\n",
    "        if keep_prob is not None:\n",
    "            self.keep_prob = keep_prob\n",
    "        w, h = tf.cast(self.w, tf.float32), tf.cast(self.h, tf.float32)\n",
    "        self.gamma = (1. - self.keep_prob) * (w * h) / (self.block_size ** 2) / \\\n",
    "                     ((w - self.block_size + 1) * (h - self.block_size + 1))\n",
    "\n",
    "    def _create_mask(self, input_shape):\n",
    "        sampling_mask_shape = tf.stack([input_shape[0],\n",
    "                                       self.h - self.block_size + 1,\n",
    "                                       self.w - self.block_size + 1,\n",
    "                                       self.channel])\n",
    "        mask = _bernoulli(sampling_mask_shape, self.gamma)\n",
    "        mask = tf.pad(mask, self.padding)\n",
    "        mask = tf.nn.max_pool(mask, [1, self.block_size, self.block_size, 1], [1, 1, 1, 1], 'SAME')\n",
    "        mask = 1 - mask\n",
    "        return mask\n",
    "\n",
    "\n",
    "class DropBlock3D(tf.keras.layers.Layer):\n",
    "    def __init__(self, keep_prob, block_size, scale=True, **kwargs):\n",
    "        super(DropBlock3D, self).__init__(**kwargs)\n",
    "        self.keep_prob = float(keep_prob) if isinstance(keep_prob, int) else keep_prob\n",
    "        self.block_size = int(block_size)\n",
    "        self.scale = tf.constant(scale, dtype=tf.bool) if isinstance(scale, bool) else scale\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 5\n",
    "        _, self.d, self.h, self.w, self.channel = input_shape.as_list()\n",
    "        # pad the mask\n",
    "        p1 = (self.block_size - 1) // 2\n",
    "        p0= (self.block_size - 1) - p1\n",
    "        self.padding = [[0, 0], [p0, p1], [p0, p1], [p0, p1], [0, 0]]\n",
    "        self.set_keep_prob()\n",
    "        super(DropBlock3D, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs, training=None, **kwargs):\n",
    "        def drop():\n",
    "            mask = self._create_mask(tf.shape(inputs))\n",
    "            output = inputs * mask\n",
    "            output = tf.cond(self.scale,\n",
    "                             true_fn=lambda: output * tf.cast(tf.size(mask), tf.float32) / tf.reduce_sum(mask),\n",
    "                             false_fn=lambda: output)\n",
    "            return output\n",
    "\n",
    "        if training is None:\n",
    "            training = K.learning_phase()\n",
    "        output = tf.cond(tf.logical_or(tf.logical_not(training), tf.equal(self.keep_prob, 1.0)),\n",
    "                         true_fn=lambda: inputs,\n",
    "                         false_fn=drop)\n",
    "        return output\n",
    "\n",
    "    def set_keep_prob(self, keep_prob=None):\n",
    "        \"\"\"This method only supports Eager Execution\"\"\"\n",
    "        if keep_prob is not None:\n",
    "            self.keep_prob = keep_prob\n",
    "        d, w, h = tf.cast(self.d, tf.float32), tf.cast(self.w, tf.float32), tf.cast(self.h, tf.float32)\n",
    "        self.gamma = ((1. - self.keep_prob) * (d * w * h) / (self.block_size ** 3) /\n",
    "                      ((d - self.block_size + 1) * (w - self.block_size + 1) * (h - self.block_size + 1)))\n",
    "\n",
    "    def _create_mask(self, input_shape):\n",
    "        sampling_mask_shape = tf.stack([input_shape[0],\n",
    "                                        self.d - self.block_size + 1,\n",
    "                                        self.h - self.block_size + 1,\n",
    "                                        self.w - self.block_size + 1,\n",
    "                                        self.channel])\n",
    "        mask = _bernoulli(sampling_mask_shape, self.gamma)\n",
    "        mask = tf.pad(mask, self.padding)\n",
    "        mask = tf.nn.max_pool3d(mask, [1, self.block_size, self.block_size, self.block_size, 1], [1, 1, 1, 1, 1], 'SAME')\n",
    "        mask = 1 - mask\n",
    "        return mask\n",
    "\n",
    "class DropBlock2D(tf.keras.layers.Layer):\n",
    "    def __init__(self, keep_prob, block_size, scale=True, **kwargs):\n",
    "        super(DropBlock2D, self).__init__(**kwargs)\n",
    "        self.keep_prob = float(keep_prob) if isinstance(keep_prob, int) else keep_prob\n",
    "        self.block_size = int(block_size)\n",
    "        self.scale = tf.constant(scale, dtype=tf.bool) if isinstance(scale, bool) else scale\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 4\n",
    "        _, self.h, self.w, self.channel = input_shape.as_list()\n",
    "        # pad the mask\n",
    "        p1 = (self.block_size - 1) // 2\n",
    "        p0 = (self.block_size - 1) - p1\n",
    "        self.padding = [[0, 0], [p0, p1], [p0, p1], [0, 0]]\n",
    "        self.set_keep_prob()\n",
    "        super(DropBlock2D, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs, training=None, **kwargs):\n",
    "        def drop():\n",
    "            mask = self._create_mask(tf.shape(inputs))\n",
    "            output = inputs * mask\n",
    "            output = tf.cond(self.scale,\n",
    "                             true_fn=lambda: output * tf.cast(tf.size(mask), tf.float32) / tf.reduce_sum(mask),\n",
    "                             false_fn=lambda: output)\n",
    "            return output\n",
    "\n",
    "        if training is None:\n",
    "            training = K.learning_phase()\n",
    "        output = tf.cond(tf.logical_or(tf.logical_not(training), tf.equal(self.keep_prob, 1.0)),\n",
    "                         true_fn=lambda: inputs,\n",
    "                         false_fn=drop)\n",
    "        return output\n",
    "\n",
    "    def set_keep_prob(self, keep_prob=None):\n",
    "        \"\"\"This method only supports Eager Execution\"\"\"\n",
    "        if keep_prob is not None:\n",
    "            self.keep_prob = keep_prob\n",
    "        w, h = tf.cast(self.w, tf.float32), tf.cast(self.h, tf.float32)\n",
    "        self.gamma = (1. - self.keep_prob) * (w * h) / (self.block_size ** 2) / \\\n",
    "                     ((w - self.block_size + 1) * (h - self.block_size + 1))\n",
    "\n",
    "    def _create_mask(self, input_shape):\n",
    "        sampling_mask_shape = tf.stack([input_shape[0],\n",
    "                                       self.h - self.block_size + 1,\n",
    "                                       self.w - self.block_size + 1,\n",
    "                                       self.channel])\n",
    "        mask = _bernoulli(sampling_mask_shape, self.gamma)\n",
    "        mask = tf.pad(mask, self.padding)\n",
    "        mask = tf.nn.max_pool(mask, [1, self.block_size, self.block_size, 1], [1, 1, 1, 1], 'SAME')\n",
    "        mask = 1 - mask\n",
    "        return mask\n",
    "\n",
    "\n",
    "class DropBlock3D(tf.keras.layers.Layer):\n",
    "    def __init__(self, keep_prob, block_size, scale=True, **kwargs):\n",
    "        super(DropBlock3D, self).__init__(**kwargs)\n",
    "        self.keep_prob = float(keep_prob) if isinstance(keep_prob, int) else keep_prob\n",
    "        self.block_size = int(block_size)\n",
    "        self.scale = tf.constant(scale, dtype=tf.bool) if isinstance(scale, bool) else scale\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 5\n",
    "        _, self.d, self.h, self.w, self.channel = input_shape.as_list()\n",
    "        # pad the mask\n",
    "        p1 = (self.block_size - 1) // 2\n",
    "        p0= (self.block_size - 1) - p1\n",
    "        self.padding = [[0, 0], [p0, p1], [p0, p1], [p0, p1], [0, 0]]\n",
    "        self.set_keep_prob()\n",
    "        super(DropBlock3D, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs, training=None, **kwargs):\n",
    "        def drop():\n",
    "            mask = self._create_mask(tf.shape(inputs))\n",
    "            output = inputs * mask\n",
    "            output = tf.cond(self.scale,\n",
    "                             true_fn=lambda: output * tf.cast(tf.size(mask), tf.float32) / tf.reduce_sum(mask),\n",
    "                             false_fn=lambda: output)\n",
    "            return output\n",
    "\n",
    "        if training is None:\n",
    "            training = K.learning_phase()\n",
    "        output = tf.cond(tf.logical_or(tf.logical_not(training), tf.equal(self.keep_prob, 1.0)),\n",
    "                         true_fn=lambda: inputs,\n",
    "                         false_fn=drop)\n",
    "        return output\n",
    "\n",
    "    def set_keep_prob(self, keep_prob=None):\n",
    "        \"\"\"This method only supports Eager Execution\"\"\"\n",
    "        if keep_prob is not None:\n",
    "            self.keep_prob = keep_prob\n",
    "        d, w, h = tf.cast(self.d, tf.float32), tf.cast(self.w, tf.float32), tf.cast(self.h, tf.float32)\n",
    "        self.gamma = ((1. - self.keep_prob) * (d * w * h) / (self.block_size ** 3) /\n",
    "                      ((d - self.block_size + 1) * (w - self.block_size + 1) * (h - self.block_size + 1)))\n",
    "\n",
    "    def _create_mask(self, input_shape):\n",
    "        sampling_mask_shape = tf.stack([input_shape[0],\n",
    "                                        self.d - self.block_size + 1,\n",
    "                                        self.h - self.block_size + 1,\n",
    "                                        self.w - self.block_size + 1,\n",
    "                                        self.channel])\n",
    "        mask = _bernoulli(sampling_mask_shape, self.gamma)\n",
    "        mask = tf.pad(mask, self.padding)\n",
    "        mask = tf.nn.max_pool3d(mask, [1, self.block_size, self.block_size, self.block_size, 1], [1, 1, 1, 1, 1], 'SAME')\n",
    "        mask = 1 - mask\n",
    "        return mask    \n",
    "    \n",
    "### model\n",
    "\n",
    "class UNet2D2D(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, regularization=None, regularization_parameters=None):\n",
    "        super().__init__()\n",
    "        self.depth = 5\n",
    "        self.regularization = regularization\n",
    "        self.regularization_parameters = regularization_parameters\n",
    "        self.kernel_regularizer = None\n",
    "        if regularization is not None:\n",
    "            if regularization == 'l2':\n",
    "                self.kernel_regularizer = tf.keras.regularizers.l2(*regularization_parameters)\n",
    "            elif regularization == 'l1':\n",
    "                self.kernel_regularizer = tf.keras.regularizers.l1(*regularization_parameters)\n",
    "            elif regularization == 'l1_l2':\n",
    "                self.kernel_regularizer = tf.keras.regularizers.l1_l2(*regularization_parameters)\n",
    "\n",
    "        self.conv3d_1_1 = tf.keras.layers.Conv3D(filters=1, kernel_size=3, strides=1, padding='same', name='conv3d_1_1',\n",
    "                                                 kernel_regularizer=self.kernel_regularizer)\n",
    "\n",
    "    def _add_regularization_layer(self, input_layer, name_suffix, input_type='2d', activation='relu'):\n",
    "\n",
    "        regularization_layer = None\n",
    "\n",
    "        if self.regularization == 'batch_norm':\n",
    "            layer_name = \"Batch_Norm_\" + name_suffix\n",
    "            if hasattr(self, layer_name):\n",
    "                batch_norm_layer = getattr(self, layer_name)\n",
    "            else:\n",
    "                batch_norm_layer = tf.keras.layers.BatchNormalization(-1, name=layer_name)\n",
    "                setattr(self, layer_name, batch_norm_layer)\n",
    "            regularization_layer = batch_norm_layer(input_layer)\n",
    "\n",
    "        elif self.regularization == 'instance_norm':\n",
    "            layer_name = \"Instance_Norm_\" + name_suffix\n",
    "            if hasattr(self, layer_name):\n",
    "                instance_norm_layer = getattr(self, layer_name)\n",
    "            else:\n",
    "                instance_norm_layer = InstanceNormalization(-1, name=layer_name)\n",
    "                setattr(self, layer_name, instance_norm_layer)\n",
    "            regularization_layer = instance_norm_layer(input_layer)\n",
    "\n",
    "        elif self.regularization == 'dropout':\n",
    "            layer_name = \"Dropout_\" + name_suffix\n",
    "            if hasattr(self, layer_name):\n",
    "                dropout_layer = getattr(self, layer_name)\n",
    "            else:\n",
    "                dropout_layer = tf.keras.layers.Dropout(*self.regularization_parameters, name=layer_name)\n",
    "                setattr(self, layer_name, dropout_layer)\n",
    "            regularization_layer = dropout_layer(input_layer)\n",
    "\n",
    "        elif self.regularization == 'dropblock':\n",
    "            if input_type == '1d':\n",
    "                return input_layer\n",
    "            elif input_type == '2d':\n",
    "                layer_name = \"DropBlock_\" + name_suffix\n",
    "                if hasattr(self, layer_name):\n",
    "                    dropblock_layer = getattr(self, layer_name)\n",
    "                else:\n",
    "                    dropblock_layer = DropBlock2D(*self.regularization_parameters, name=layer_name)\n",
    "                    setattr(self, layer_name, dropblock_layer)\n",
    "                regularization_layer = dropblock_layer(input_layer)\n",
    "\n",
    "            elif input_type == '3d':\n",
    "                layer_name = \"DropBlock_\" + name_suffix\n",
    "                if hasattr(self, layer_name):\n",
    "                    dropblock_layer = getattr(self, layer_name)\n",
    "                else:\n",
    "                    dropblock_layer = DropBlock3D(*self.regularization_parameters, name=layer_name)\n",
    "                    setattr(self, layer_name, dropblock_layer)\n",
    "                regularization_layer = dropblock_layer(input_layer)\n",
    "\n",
    "        if regularization_layer is not None:\n",
    "            output = tf.keras.layers.Activation(activation=activation)(regularization_layer)\n",
    "        else:\n",
    "            output = tf.keras.layers.Activation(activation=activation)(input_layer)\n",
    "        return output\n",
    "\n",
    "    def _get_convolution_block(self, input_layer, filters, kernel_size=3, strides=1, padding='same',\n",
    "                               name_prefix='l_', activation='relu'):\n",
    "\n",
    "        in_b, in_w, in_h, in_t, in_c = input_layer.get_shape().as_list()\n",
    "        permute_layer_name_1 = name_prefix + \"Permute_{}_1\".format(filters)\n",
    "        if hasattr(self, permute_layer_name_1):\n",
    "            permute_layer_1 = getattr(self, permute_layer_name_1)\n",
    "        else:\n",
    "            permute_layer_1 = tf.keras.layers.Permute((2, 1, 3, 4), name=permute_layer_name_1)\n",
    "            setattr(self, permute_layer_name_1, permute_layer_1)\n",
    "\n",
    "        permute_layer_1 = permute_layer_1(input_layer)\n",
    "\n",
    "        reshape_layer_1 = tf.reshape(permute_layer_1, shape=(-1,\n",
    "                                                             in_w, in_t,\n",
    "                                                             in_c))\n",
    "\n",
    "        conv2d_layer_name_1 = name_prefix + \"Conv2D_{}_1\".format(filters)\n",
    "        if hasattr(self, conv2d_layer_name_1):\n",
    "            conv2d_1 = getattr(self, conv2d_layer_name_1)\n",
    "        else:\n",
    "            conv2d_1 = tf.keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, strides=strides,\n",
    "                                              padding=padding,name=conv2d_layer_name_1,\n",
    "                                              kernel_regularizer=self.kernel_regularizer, data_format='channels_last')\n",
    "            setattr(self, conv2d_layer_name_1, conv2d_1)\n",
    "\n",
    "        conv2d_1 = conv2d_1(reshape_layer_1)\n",
    "        conv2d_1 = self._add_regularization_layer(conv2d_1, name_suffix=conv2d_layer_name_1, activation=activation)\n",
    "\n",
    "        reshape_layer_2 = tf.reshape(conv2d_1, shape=(-1, in_h,\n",
    "                                                      in_w, in_t, filters))\n",
    "\n",
    "        permute_layer_name_2 = name_prefix + \"Permute_{}_2\".format(filters)\n",
    "        if hasattr(self, permute_layer_name_2):\n",
    "            permute_layer_2 = getattr(self, permute_layer_name_2)\n",
    "        else:\n",
    "            permute_layer_2 = tf.keras.layers.Permute((2, 1, 3, 4), name=permute_layer_name_2)\n",
    "            setattr(self, permute_layer_name_2, permute_layer_2)\n",
    "        permute_layer_2 = permute_layer_2(reshape_layer_2)\n",
    "\n",
    "        reshape_layer_3 = tf.keras.backend.reshape(permute_layer_2, shape=(-1, in_h,\n",
    "                                                                           in_t, filters))\n",
    "        conv2d_layer_name_2 = name_prefix + \"Conv2D_{}_2\".format(filters)\n",
    "        if hasattr(self, conv2d_layer_name_2):\n",
    "            conv2d_2 = getattr(self, conv2d_layer_name_2)\n",
    "        else:\n",
    "            conv2d_2 = tf.keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding=padding,\n",
    "                                              name=conv2d_layer_name_2,\n",
    "                                              kernel_regularizer=self.kernel_regularizer, data_format='channels_last')\n",
    "            setattr(self, conv2d_layer_name_2, conv2d_2)\n",
    "\n",
    "        conv2d_2 = conv2d_2(reshape_layer_3)\n",
    "        conv2d_2 = self._add_regularization_layer(conv2d_2, name_suffix=conv2d_layer_name_2, activation=activation)\n",
    "\n",
    "        reshape_layer_4 = tf.keras.backend.reshape(conv2d_2, shape=(-1, in_w, in_h, in_t, filters))\n",
    "\n",
    "        return reshape_layer_4\n",
    "\n",
    "    def _get_convolution_transpose_layer(self, input_layer, filters, kernel_size=3, strides=(2, 2, 1), padding='same',\n",
    "                                         name_prefix='r_', activation='relu'):\n",
    "\n",
    "        conv3d_transpose_layer_name = name_prefix + \"UpConv3D_{}\".format(filters)\n",
    "        if hasattr(self, conv3d_transpose_layer_name):\n",
    "            conv3d_transpose = getattr(self, conv3d_transpose_layer_name)\n",
    "        else:\n",
    "            conv3d_transpose = tf.keras.layers.Convolution3DTranspose(filters=filters, kernel_size=kernel_size,\n",
    "                                                                      strides=strides, padding=padding,\n",
    "                                                                      name=conv3d_transpose_layer_name,\n",
    "                                                                      kernel_regularizer=self.kernel_regularizer)\n",
    "\n",
    "            setattr(self, conv3d_transpose_layer_name, conv3d_transpose)\n",
    "        conv3d_transpose = conv3d_transpose(input_layer)\n",
    "        conv3d_transpose = self._add_regularization_layer(conv3d_transpose, name_suffix=conv3d_transpose_layer_name,\n",
    "                                                          input_type='3d', activation=activation)\n",
    "        return conv3d_transpose\n",
    "\n",
    "    def _get_max_pool_3d_layer(self, filters, pool_size=(2, 2, 1), strides=(2, 2, 1), padding='same',\n",
    "                               name_prefix='l_'):\n",
    "\n",
    "        maxpool_3d_layer_name = name_prefix + \"MaxPool3D_{}\".format(filters)\n",
    "        if hasattr(self, maxpool_3d_layer_name):\n",
    "            maxpool_3d = getattr(self, maxpool_3d_layer_name)\n",
    "        else:\n",
    "            maxpool_3d = tf.keras.layers.MaxPooling3D(pool_size=pool_size, strides=strides, padding=padding,\n",
    "                                                      name=maxpool_3d_layer_name)\n",
    "            setattr(self, maxpool_3d_layer_name, maxpool_3d)\n",
    "        return maxpool_3d\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = tf.keras.backend.expand_dims(inputs, axis=-1)\n",
    "        current_layer = inputs\n",
    "        level = []\n",
    "\n",
    "        for depth in range(self.depth):\n",
    "            filters = 32 * 2 ** depth\n",
    "            first_layer = self._get_convolution_block(input_layer=current_layer, filters=filters)\n",
    "            if depth < self.depth - 1:\n",
    "                current_layer = self._get_max_pool_3d_layer(filters=filters)(first_layer)\n",
    "                level.append([first_layer, current_layer])\n",
    "            else:\n",
    "                current_layer = first_layer\n",
    "                level.append([first_layer])\n",
    "\n",
    "        for depth in range(self.depth - 2, -1, -1):\n",
    "            filters = 32 * 2 ** depth\n",
    "            up_convolution_layer = self._get_convolution_transpose_layer(input_layer=current_layer, filters=filters,\n",
    "                                                                         kernel_size=2)\n",
    "            concat_layer = tf.keras.layers.concatenate([level[depth][0], up_convolution_layer], axis=-1)\n",
    "            current_layer = self._get_convolution_block(input_layer=concat_layer, filters=filters, name_prefix='r_')\n",
    "\n",
    "        conv3d_1_1 = self.conv3d_1_1(current_layer)\n",
    "        conv3d_1_1 = self._add_regularization_layer(conv3d_1_1, name_suffix='conv3d_1_1', input_type='3d',\n",
    "                                                    activation='relu')\n",
    "\n",
    "        sum = tf.keras.layers.add([conv3d_1_1, inputs])\n",
    "        update = tf.keras.activations.relu(sum)\n",
    "        output = tf.keras.backend.squeeze(update, -1)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5af9d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 605)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "image_path = \"data_ex.ppm\"  \n",
    "image = Image.open(image_path)\n",
    "\n",
    "print(image.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0a817c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code here won't work\n",
    "\n",
    "for training_path in training_paths:\n",
    "    print(training_path)\n",
    "    for task_name, path in get_subdirectories(training_path):\n",
    "        print(task_name)\n",
    "        for dirpath, dirnames, filenames in os.walk(path):\n",
    "            for filename in [f for f in filenames if f.endswith(\".h5\")]:\n",
    "                training_result = os.path.join(dirpath, filename)\n",
    "                metric = calculate_metrics(training_result)\n",
    "                result.append((task_name, metric))\n",
    "                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2af282e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2297e024",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
